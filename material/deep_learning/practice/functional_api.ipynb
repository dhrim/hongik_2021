{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "functional_api.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c503DSvxvOU5"
      },
      "source": [
        "# 이전 CNN MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlMkT8axIoi"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puN5QRLz2toU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f50304b9-5514-44a6-9946-7edb7d2c7316"
      },
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = raw_train_x/255\n",
        "test_x = raw_test_x/255\n",
        "\n",
        "train_x = train_x.reshape((60000, 28, 28, 1))\n",
        "test_x = test_x.reshape((10000, 28, 28, 1))\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkrsyGy2Ixk2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5f75fb1b-1af0-4327-d848-ec1d18c2358f"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Input((28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9e5145cb283a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuW2ftNT2trB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "bfb70fd5-ac31-4cae-ca46-b438901dffad"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1cbfdf1ef8ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6yj3_5GI064"
      },
      "source": [
        "# Functional API 타입 CNN MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRkSjvdSkgfc"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1C6Ev9hI7JD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1adc2f54-2e15-489a-d3d7-df0ca669ed90"
      },
      "source": [
        "# model = keras.Sequential()\n",
        "# model.add(Input((28,28,1)))\n",
        "# model.add(Conv2D(32, (3, 3)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Conv2D(64, (3, 3)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "input = Input((28,28,1))\n",
        "x = Conv2D(32, (3,3))(input)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Conv2D(32, (3,3))(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(input, output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH90FFocI7GG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "886e72f1-83a3-40c2-8fba-cc19eb51d4de"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                8010      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 17,798\n",
            "Trainable params: 17,798\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.6246 - acc: 0.7989\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1531 - acc: 0.9543\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1111 - acc: 0.9671\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0910 - acc: 0.9731\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0780 - acc: 0.9771\n",
            "10000/10000 [==============================] - 1s 84us/sample - loss: 0.0749 - acc: 0.9762\n",
            "loss= 0.07491177502721548\n",
            "acc= 0.9762\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRB8AVGJK_Iz"
      },
      "source": [
        "# 다중 입력\n",
        "\n",
        "copy from https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR8fS0GoE3m_"
      },
      "source": [
        "## 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6UWmnjzI7DS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e6a5353d-7db0-46ef-e932-51a76009da5f"
      },
      "source": [
        "!git clone https://github.com/emanhamed/Houses-dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Houses-dataset'...\n",
            "remote: Enumerating objects: 2166, done.\u001b[K\n",
            "remote: Total 2166 (delta 0), reused 0 (delta 0), pack-reused 2166\u001b[K\n",
            "Receiving objects: 100% (2166/2166), 176.26 MiB | 13.77 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgLmgfnJFJkR"
      },
      "source": [
        "```\n",
        "Houses-dataset/\n",
        "  Houses Dataset/\n",
        "    100_bathroom.jpg\n",
        "    100_bedroom.jpg\n",
        "    ...\n",
        "    HousesInfo.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnppMLOAFgtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d7123369-3dce-436f-ccc1-412445adf9b0"
      },
      "source": [
        "!head 'Houses-dataset/Houses Dataset/HousesInfo.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 4 4053 85255 869500\n",
            "4 3 3343 36372 865200\n",
            "3 4 3923 85266 889000\n",
            "5 5 4022 85262 910000\n",
            "3 4 4116 85266 971226\n",
            "4 5 4581 85266 1249000\n",
            "3 4 2544 85262 799000\n",
            "4 5 5524 85266 1698000\n",
            "3 4 4229 85255 1749000\n",
            "4 5 3550 85262 1500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmpEfpGogwJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb1bb6ba-e63c-4e53-c69b-0a9237b93097"
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEteIEtNFwvP"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def load_house_attributes(inputPath):\n",
        "\n",
        "\tcols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\n",
        "\tdf = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)\n",
        " \n",
        "\t# determine (1) the unique zip codes and (2) the number of data\n",
        "\t# points with each zip code\n",
        "\tzipcodes = df[\"zipcode\"].value_counts().keys().tolist()\n",
        "\tcounts = df[\"zipcode\"].value_counts().tolist()\n",
        " \n",
        "\t# loop over each of the unique zip codes and their corresponding\n",
        "\t# count\n",
        "\tfor (zipcode, count) in zip(zipcodes, counts):\n",
        "\t\t# the zip code counts for our housing dataset is *extremely*\n",
        "\t\t# unbalanced (some only having 1 or 2 houses per zip code)\n",
        "\t\t# so let's sanitize our data by removing any houses with less\n",
        "\t\t# than 25 houses per zip code\n",
        "\t\tif count < 25:\n",
        "\t\t\tidxs = df[df[\"zipcode\"] == zipcode].index\n",
        "\t\t\tdf.drop(idxs, inplace=True)\n",
        "   \n",
        "\t# return the data frame\n",
        "\treturn df\n",
        "\n",
        "def process_house_attributes(df, train, test):\n",
        "\t# initialize the column names of the continuous data\n",
        "\tcontinuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n",
        "\n",
        "\t# performin min-max scaling each continuous feature column to\n",
        "\t# the range [0, 1]\n",
        "\tcs = MinMaxScaler()\n",
        "\ttrainContinuous = cs.fit_transform(train[continuous])\n",
        "\ttestContinuous = cs.transform(test[continuous])\n",
        " \n",
        "\t# one-hot encode the zip code categorical data (by definition of\n",
        "\t# one-hot encoding, all output features are now in the range [0, 1])\n",
        "\tzipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
        "\ttrainCategorical = zipBinarizer.transform(train[\"zipcode\"])\n",
        "\ttestCategorical = zipBinarizer.transform(test[\"zipcode\"])\n",
        " \n",
        "\t# construct our training and testing data points by concatenating\n",
        "\t# the categorical features with the continuous features\n",
        "\ttrainX = np.hstack([trainCategorical, trainContinuous])\n",
        "\ttestX = np.hstack([testCategorical, testContinuous])\n",
        " \n",
        "\t# return the concatenated training and testing data\n",
        "\treturn (trainX, testX)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I8GQV4mFwrk"
      },
      "source": [
        "def load_house_images(df, inputPath):\n",
        "\n",
        "\t# initialize our images array (i.e., the house images themselves)\n",
        "\timages = []\n",
        "\n",
        "\t# loop over the indexes of the houses\n",
        "\tfor i in df.index.values:\n",
        "\t\t# find the four images for the house and sort the file paths,\n",
        "\t\t# ensuring the four are always in the *same order*\n",
        "\t\tbasePath = os.path.sep.join([inputPath, \"{}_*\".format(i + 1)])\n",
        "\t\thousePaths = sorted(list(glob.glob(basePath)))\n",
        "  \n",
        "\t\t# initialize our list of input images along with the output image\n",
        "\t\t# after *combining* the four input images\n",
        "\t\tinputImages = []\n",
        "\t\toutputImage = np.zeros((64, 64, 3), dtype=\"uint8\")\n",
        "  \n",
        "\t\t# loop over the input house paths\n",
        "\t\tfor housePath in housePaths:\n",
        "\t\t\t# load the input image, resize it to be 32 32, and then\n",
        "\t\t\t# update the list of input images\n",
        "\t\t\timage = cv2.imread(housePath)\n",
        "\t\t\timage = cv2.resize(image, (32, 32))\n",
        "\t\t\tinputImages.append(image)\n",
        "   \n",
        "\t\t# tile the four input images in the output image such the first\n",
        "\t\t# image goes in the top-right corner, the second image in the\n",
        "\t\t# top-left corner, the third image in the bottom-right corner,\n",
        "\t\t# and the final image in the bottom-left corner\n",
        "\t\toutputImage[0:32, 0:32] = inputImages[0]\n",
        "\t\toutputImage[0:32, 32:64] = inputImages[1]\n",
        "\t\toutputImage[32:64, 32:64] = inputImages[2]\n",
        "\t\toutputImage[32:64, 0:32] = inputImages[3]\n",
        "\n",
        "\t\t# add the tiled image to our set of images the network will be\n",
        "\t\t# trained on\n",
        "\t\timages.append(outputImage)\n",
        "  \n",
        "\t# return our set of images\n",
        "\treturn np.array(images)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEJ6Gp0qHVi6"
      },
      "source": [
        "### 값 정보 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke6Xu-5PGdkr"
      },
      "source": [
        "df = load_house_attributes(\"Houses-dataset/Houses Dataset/HousesInfo.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouQ27yABHR2w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5830b3d2-eafa-48f6-942c-a68e1ef63446"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>area</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2520</td>\n",
              "      <td>93446</td>\n",
              "      <td>789000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1802</td>\n",
              "      <td>93446</td>\n",
              "      <td>365000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2146</td>\n",
              "      <td>93446</td>\n",
              "      <td>455000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>4</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2464</td>\n",
              "      <td>91901</td>\n",
              "      <td>599000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1845</td>\n",
              "      <td>91901</td>\n",
              "      <td>529800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    bedrooms  bathrooms  area  zipcode   price\n",
              "30         5        3.0  2520    93446  789000\n",
              "32         3        2.0  1802    93446  365000\n",
              "39         3        3.0  2146    93446  455000\n",
              "80         4        2.5  2464    91901  599000\n",
              "81         2        2.0  1845    91901  529800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-xIyIR1HZiE"
      },
      "source": [
        "### 영상 데이터 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuZ-lxe_Gde4"
      },
      "source": [
        "images = load_house_images(df, \"Houses-dataset/Houses Dataset/\")\n",
        "images = images/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZhmpoc8HNfQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24136eb0-c8ad-4f8c-c97d-cd5525ce7782"
      },
      "source": [
        "print(images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(362, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW9H5fZuHNbW"
      },
      "source": [
        "(trainAttrX, testAttrX, trainImagesX, testImagesX) = train_test_split(df, images, test_size=0.25, random_state=42)\n",
        "\n",
        "maxPrice = trainAttrX[\"price\"].max()\n",
        "trainY = trainAttrX[\"price\"] / maxPrice\n",
        "testY = testAttrX[\"price\"] / maxPrice\n",
        "(trainAttrX, testAttrX) = process_house_attributes(df, trainAttrX, testAttrX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoR7qloQHNYn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "765a05fc-acf7-4571-d284-3db5dc1ad913"
      },
      "source": [
        "print(\"tainAttrX.shape=\", trainAttrX.shape)\n",
        "print(\"trainImagesX.shape=\", trainImagesX.shape)\n",
        "print(\"trainY.shape=\", trainY.shape)\n",
        "print(\"testAttrX.shape=\", testAttrX.shape)\n",
        "print(\"testImageX.shape=\", testImagesX.shape)\n",
        "print(\"testY.shape=\", testY.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tainAttrX.shape= (271, 10)\n",
            "trainImagesX.shape= (271, 64, 64, 3)\n",
            "trainY.shape= (271,)\n",
            "testAttrX.shape= (91, 10)\n",
            "testImageX.shape= (91, 64, 64, 3)\n",
            "testY.shape= (91,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZclMyzHFwpA"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kow-UjvTIlO7"
      },
      "source": [
        "## 개별 모델로 학습 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMiM6S1aJDdi"
      },
      "source": [
        "### 속성 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7ABhyiqFwj7"
      },
      "source": [
        "input = Input(trainAttrX[0].shape)\n",
        "x = Dense(10, activation='relu')(input)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "output = Dense(1)(x)\n",
        "\n",
        "attr_model = Model(input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roratdC_JdVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "2d29e1ab-9d78-4942-d1c0-9e29398b4654"
      },
      "source": [
        "attr_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "attr_model.summary()\n",
        "\n",
        "attr_model.fit(trainAttrX, trainY, epochs=100, verbose=0, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 231\n",
            "Trainable params: 231\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0812404e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk5WagwnJdTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bdbf37b-a8af-40c4-a712-e2068aaea59a"
      },
      "source": [
        "preds = attr_model.predict(testAttrX)\n",
        "\n",
        "diff = preds.flatten() - testY\n",
        "percentDiff = (diff / testY) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        "\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        "\n",
        "print(\"[INFO] mean: {:.2f}%, std: {:.2f}\".format(mean, std))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] mean: 38.70%, std: 61.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L6Nr-1ZJdP_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY4cMiohJFKc"
      },
      "source": [
        "### 영상 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEbOBK0ULRlT"
      },
      "source": [
        "input = Input(trainImagesX[0].shape)\n",
        "x = Conv2D(32, (3,3))(input)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Conv2D(32, (3,3))(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "output = Dense(1)(x)\n",
        "\n",
        "image_model = Model(input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jprcg41pLRhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "80c246de-011b-41cd-d7ac-575399063123"
      },
      "source": [
        "image_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "image_model.summary()\n",
        "\n",
        "image_model.fit(trainImagesX, trainY, epochs=100, verbose=0, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 29, 29, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                62730     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 72,995\n",
            "Trainable params: 72,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0810c4320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OROOOvr9LRet",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1216f1e0-25e2-449c-b983-fa7dadc115e2"
      },
      "source": [
        "preds = image_model.predict(testImagesX)\n",
        "\n",
        "diff = preds.flatten() - testY\n",
        "percentDiff = (diff / testY) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        "\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        "\n",
        "print(\"[INFO] mean: {:.2f}%, std: {:.2f}\".format(mean, std))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] mean: 96.52%, std: 149.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7DX0yusIn78"
      },
      "source": [
        "## 다중 입력 모델로 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7iDDfb-LRb6"
      },
      "source": [
        "attr_input = Input(trainAttrX[0].shape)\n",
        "x = Dense(10, activation='relu')(attr_input)\n",
        "attr_out = Dense(10, activation='linear')(x)\n",
        "\n",
        "image_input = Input(trainImagesX[0].shape)\n",
        "x = Conv2D(32, (3,3))(image_input)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Conv2D(32, (3,3))(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "image_output = Dense(10, activation='linear')(x)\n",
        "\n",
        "combined_input = concatenate([attr_out, image_output])\n",
        "\n",
        "x = Dense(4, activation=\"relu\")(combined_input)\n",
        "output = Dense(1)(x)\n",
        "\n",
        "\n",
        "combined_model = Model([attr_input, image_input], output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fVpru2CLRYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "b6ebdd8f-1940-4a43-cae6-d6355fcbff2a"
      },
      "source": [
        "combined_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "combined_model.summary()\n",
        "\n",
        "combined_model.fit([trainAttrX, trainImagesX], trainY, epochs=100, verbose=0, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 62, 62, 32)   896         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 31, 31, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 29, 29, 32)   9248        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 32)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 6272)         0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           110         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           62730       flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 10)           110         dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 10)           110         dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20)           0           dense_10[0][0]                   \n",
            "                                                                 dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 4)            84          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1)            5           dense_13[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 73,293\n",
            "Trainable params: 73,293\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0810eecf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdJXO5maFwh0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e78b393e-283b-4314-c259-04f130f78f6c"
      },
      "source": [
        "preds = combined_model.predict([testAttrX, testImagesX])\n",
        "\n",
        "diff = preds.flatten() - testY\n",
        "percentDiff = (diff / testY) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        "\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        "\n",
        "print(\"[INFO] mean: {:.2f}%, std: {:.2f}\".format(mean, std))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] mean: 115.42%, std: 189.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAh3boxuFwez"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejOg9i5KMU28"
      },
      "source": [
        "# 다중 출력\n",
        "\n",
        "copy from https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLnb63o5ottv"
      },
      "source": [
        "## 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBXMpbDn76uf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "102a84c1-c5dd-4425-d39f-717e083afc34"
      },
      "source": [
        "!wget https://github.com/dhrim/hongik_2021/raw/master/multi_label_classification/fashion_dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-16 02:46:57--  https://github.com/dhrim/hongik_2021/raw/master/multi_label_classification/fashion_dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dhrim/hongik_2021/master/multi_label_classification/fashion_dataset.zip [following]\n",
            "--2020-07-16 02:46:58--  https://raw.githubusercontent.com/dhrim/hongik_2021/master/multi_label_classification/fashion_dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26991216 (26M) [application/zip]\n",
            "Saving to: ‘fashion_dataset.zip’\n",
            "\n",
            "fashion_dataset.zip 100%[===================>]  25.74M  35.8MB/s    in 0.7s    \n",
            "\n",
            "2020-07-16 02:47:00 (35.8 MB/s) - ‘fashion_dataset.zip’ saved [26991216/26991216]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFt96FMqvjah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "4cc05ab5-c9f1-4c5f-9174-37c29e8dccda"
      },
      "source": [
        "!ls -alh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 26M\n",
            "drwxr-xr-x 1 root root 4.0K Jul 16 02:46 .\n",
            "drwxr-xr-x 1 root root 4.0K Jul 16 02:33 ..\n",
            "drwxr-xr-x 1 root root 4.0K Jul 13 16:14 .config\n",
            "-rw-r--r-- 1 root root  26M Jul 16 02:47 fashion_dataset.zip\n",
            "drwxr-xr-x 4 root root 4.0K Jul 16 02:42 Houses-dataset\n",
            "drwxr-xr-x 1 root root 4.0K Jul 10 16:29 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYCavDIjh5RK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c08c082-83b4-4153-ca07-37ddac4a242c"
      },
      "source": [
        "!unzip fashion_dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  fashion_dataset.zip\n",
            "   creating: fashion_dataset/\n",
            "   creating: fashion_dataset/black_jeans/\n",
            "  inflating: fashion_dataset/black_jeans/00000000.jpg  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/fashion_dataset/\n",
            "   creating: __MACOSX/fashion_dataset/black_jeans/\n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000000.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000004.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000004.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000006.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000006.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000007.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000007.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000009.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000009.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000010.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000010.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000011.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000011.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000014.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000014.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000015.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000015.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000016.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000016.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000017.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000017.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000018.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000018.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000019.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000019.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000040.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000040.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000041.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000041.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000047.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000047.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000048.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000048.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000049.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000049.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000051.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000051.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000054.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000054.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000055.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000055.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000056.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000056.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000057.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000057.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000060.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000060.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000061.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000061.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000064.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000064.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000065.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000065.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000066.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000066.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000067.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000067.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000068.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000068.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000071.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000071.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000074.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000074.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000075.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000075.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000076.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000076.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000078.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000078.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000079.png  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000079.png  \n",
            "  inflating: fashion_dataset/black_jeans/00000080.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000080.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000081.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000081.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000084.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000084.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000085.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000085.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000086.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000086.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000088.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000088.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000089.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000089.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000090.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000090.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000094.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000094.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000095.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000095.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000096.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000096.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000097.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000097.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000098.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000098.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000100.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000100.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000101.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000101.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000104.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000104.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000105.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000105.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000107.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000107.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000108.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000108.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000110.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000110.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000111.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000111.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000117.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000117.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000118.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000118.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000140.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000140.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000141.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000141.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000144.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000144.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000145.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000145.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000146.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000146.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000148.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000148.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000149.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000149.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000150.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000150.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000151.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000151.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000155.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000155.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000156.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000156.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000157.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000157.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000159.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000159.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000160.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000160.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000164.JPG  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000164.JPG  \n",
            "  inflating: fashion_dataset/black_jeans/00000166.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000166.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000167.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000167.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000168.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000168.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000169.png  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000169.png  \n",
            "  inflating: fashion_dataset/black_jeans/00000171.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000171.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000176.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000176.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000177.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000177.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000184.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000184.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000185.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000185.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000186.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000186.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000189.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000189.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000190.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000190.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000191.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000191.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000194.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000194.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000195.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000195.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000196.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000196.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000197.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000197.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000198.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000198.jpg  \n",
            "  inflating: fashion_dataset/black_jeans/00000199.jpg  \n",
            "  inflating: __MACOSX/fashion_dataset/black_jeans/._00000199.jpg  \n",
            "   creating: fashion_dataset/black_shoes/\n",
            "  inflating: fashion_dataset/black_shoes/00000000.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000001.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000004.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000005.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000006.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000007.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000008.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000009.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000010.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000011.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000015.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000016.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000017.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000018.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000019.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000040.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000041.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000044.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000045.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000048.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000049.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000051.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000054.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000055.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000056.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000057.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000059.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000060.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000061.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000064.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000065.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000066.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000067.png  \n",
            "  inflating: fashion_dataset/black_shoes/00000068.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000069.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000070.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000071.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000075.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000076.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000078.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000079.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000080.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000081.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000084.JPG  \n",
            "  inflating: fashion_dataset/black_shoes/00000086.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000087.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000088.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000089.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000090.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000091.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000094.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000095.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000096.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000097.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000098.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000099.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000100.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000104.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000105.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000106.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000107.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000108.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000109.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000110.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000111.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000114.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000115.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000116.png  \n",
            "  inflating: fashion_dataset/black_shoes/00000117.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000118.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000119.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000140.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000141.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000144.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000145.JPG  \n",
            "  inflating: fashion_dataset/black_shoes/00000146.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000147.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000148.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000149.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000150.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000151.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000154.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000156.JPG  \n",
            "  inflating: fashion_dataset/black_shoes/00000157.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000158.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000159.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000160.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000161.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000165.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000166.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000168.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000169.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000170.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000171.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000174.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000175.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000176.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000177.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000179.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000180.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000181.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000185.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000186.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000187.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000188.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000189.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000190.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000191.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000194.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000195.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000196.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000198.jpg  \n",
            "  inflating: fashion_dataset/black_shoes/00000199.gif  \n",
            "   creating: fashion_dataset/blue_dress/\n",
            "  inflating: fashion_dataset/blue_dress/00000000.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000001.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000004.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000005.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000007.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000008.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000009.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000010.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000011.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000014.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000015.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000016.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000017.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000018.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000019.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000040.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000044.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000045.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000046.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000047.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000048.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000049.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000050.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000051.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000054.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000056.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000057.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000058.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000059.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000060.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000061.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000064.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000065.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000066.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000067.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000068.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000069.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000071.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000074.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000075.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000076.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000077.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000079.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000080.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000081.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000084.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000085.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000086.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000087.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000088.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000089.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000090.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000091.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000094.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000095.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000097.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000100.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000101.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000104.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000105.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000106.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000107.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000108.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000109.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000110.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000111.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000114.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000115.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000116.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000117.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000118.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000119.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000141.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000144.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000146.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000147.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000148.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000149.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000150.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000155.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000156.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000157.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000158.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000159.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000160.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000161.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000164.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000166.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000167.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000168.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000169.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000170.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000171.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000174.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000176.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000177.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000178.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000179.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000180.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000181.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000184.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000185.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000186.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000187.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000188.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000189.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000190.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000191.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000194.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000195.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000196.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000197.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000198.jpg  \n",
            "  inflating: fashion_dataset/blue_dress/00000199.jpg  \n",
            "   creating: fashion_dataset/blue_jeans/\n",
            "  inflating: fashion_dataset/blue_jeans/00000000.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000004.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000005.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000006.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000007.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000009.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000010.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000011.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000014.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000015.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000016.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000017.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000019.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000040.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000041.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000044.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000045.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000046.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000047.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000049.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000050.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000051.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000054.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000055.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000056.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000057.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000058.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000059.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000061.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000064.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000065.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000067.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000069.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000071.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000074.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000077.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000080.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000081.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000084.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000086.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000087.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000088.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000089.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000090.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000091.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000094.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000095.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000096.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000097.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000098.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000099.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000100.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000104.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000105.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000106.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000108.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000109.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000110.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000111.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000117.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000118.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000119.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000140.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000141.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000144.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000146.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000148.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000149.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000150.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000151.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000154.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000155.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000156.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000157.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000158.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000159.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000160.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000161.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000164.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000165.png  \n",
            "  inflating: fashion_dataset/blue_jeans/00000167.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000168.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000169.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000170.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000171.png  \n",
            "  inflating: fashion_dataset/blue_jeans/00000174.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000175.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000177.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000180.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000186.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000187.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000188.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000189.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000190.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000194.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000195.png  \n",
            "  inflating: fashion_dataset/blue_jeans/00000196.jpg  \n",
            "  inflating: fashion_dataset/blue_jeans/00000198.jpg  \n",
            "   creating: fashion_dataset/blue_shirt/\n",
            "  inflating: fashion_dataset/blue_shirt/00000000.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000001.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000004.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000005.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000006.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000007.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000008.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000009.JPG  \n",
            "  inflating: fashion_dataset/blue_shirt/00000010.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000011.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000014.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000015.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000016.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000017.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000018.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000019.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000040.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000041.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000044.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000045.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000046.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000049.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000050.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000051.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000054.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000055.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000056.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000057.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000058.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000060.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000061.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000064.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000065.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000067.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000068.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000069.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000070.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000071.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000074.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000075.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000078.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000079.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000080.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000081.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000084.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000085.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000086.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000088.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000089.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000090.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000091.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000094.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000095.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000096.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000097.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000098.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000099.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000100.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000101.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000104.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000105.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000106.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000107.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000108.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000109.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000110.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000111.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000114.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000115.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000116.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000117.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000118.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000119.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000140.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000141.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000144.JPG  \n",
            "  inflating: fashion_dataset/blue_shirt/00000146.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000147.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000148.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000149.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000151.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000154.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000155.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000156.JPG  \n",
            "  inflating: fashion_dataset/blue_shirt/00000157.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000158.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000159.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000160.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000161.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000164.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000165.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000166.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000167.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000168.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000169.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000171.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000174.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000175.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000178.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000179.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000180.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000181.png  \n",
            "  inflating: fashion_dataset/blue_shirt/00000184.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000185.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000186.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000187.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000190.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000191.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000194.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000195.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000196.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000197.jpg  \n",
            "  inflating: fashion_dataset/blue_shirt/00000198.jpg  \n",
            "   creating: fashion_dataset/red_dress/\n",
            "  inflating: fashion_dataset/red_dress/00000000.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000001.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000004.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000005.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000006.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000007.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000008.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000009.JPG  \n",
            "  inflating: fashion_dataset/red_dress/00000010.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000011.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000014.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000015.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000016.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000017.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000018.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000019.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000040.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000041.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000044.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000045.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000046.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000047.png  \n",
            "  inflating: fashion_dataset/red_dress/00000048.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000049.png  \n",
            "  inflating: fashion_dataset/red_dress/00000050.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000051.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000054.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000055.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000056.png  \n",
            "  inflating: fashion_dataset/red_dress/00000057.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000058.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000059.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000060.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000061.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000064.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000065.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000066.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000067.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000069.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000071.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000074.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000075.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000076.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000077.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000078.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000079.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000080.JPG  \n",
            "  inflating: fashion_dataset/red_dress/00000081.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000085.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000086.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000087.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000088.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000089.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000090.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000094.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000095.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000096.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000097.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000098.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000099.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000100.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000101.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000104.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000105.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000106.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000107.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000108.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000109.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000110.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000111.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000114.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000115.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000116.gif  \n",
            "  inflating: fashion_dataset/red_dress/00000117.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000118.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000140.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000141.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000146.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000147.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000148.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000149.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000151.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000154.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000155.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000156.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000158.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000159.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000160.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000161.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000164.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000165.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000166.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000167.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000168.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000169.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000170.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000174.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000175.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000176.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000177.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000178.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000179.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000181.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000184.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000185.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000186.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000187.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000188.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000189.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000190.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000191.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000194.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000195.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000196.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000197.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000198.jpg  \n",
            "  inflating: fashion_dataset/red_dress/00000199.jpg  \n",
            "   creating: fashion_dataset/red_shirt/\n",
            "  inflating: fashion_dataset/red_shirt/00000000.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000001.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000004.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000005.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000006.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000007.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000008.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000011.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000014.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000015.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000016.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000018.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000019.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000040.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000041.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000044.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000045.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000046.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000047.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000048.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000049.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000050.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000051.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000054.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000055.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000056.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000057.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000058.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000059.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000060.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000064.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000065.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000066.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000067.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000068.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000069.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000070.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000071.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000074.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000075.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000076.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000077.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000078.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000079.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000080.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000081.png  \n",
            "  inflating: fashion_dataset/red_shirt/00000084.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000085.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000089.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000091.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000094.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000095.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000096.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000097.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000098.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000099.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000100.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000101.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000105.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000106.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000107.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000108.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000110.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000111.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000114.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000115.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000116.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000117.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000140.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000141.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000144.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000145.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000146.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000147.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000149.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000150.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000151.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000154.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000155.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000156.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000157.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000158.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000159.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000160.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000161.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000164.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000165.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000167.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000168.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000169.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000170.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000171.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000174.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000175.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000176.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000177.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000178.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000180.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000181.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000184.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000187.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000188.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000190.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000191.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000195.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000196.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000197.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000198.jpg  \n",
            "  inflating: fashion_dataset/red_shirt/00000199.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c48Y7utfiKHQ"
      },
      "source": [
        "```\n",
        "fashion_dataset/\n",
        "  black_jeans\n",
        "  black_shoes/\n",
        "  blue_dress/\n",
        "  blue_jeans\n",
        "  blue_shirt/\n",
        "  red_dress/\n",
        "  red_shirt/\n",
        "```\n",
        "\n",
        "```\n",
        "category : jeans, shoes, dress, shirt\n",
        "color : black, blue, red\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dodBjvth_d-"
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_ONY_4jtzK"
      },
      "source": [
        "IMAGE_DIMS = (96, 96, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTw_iOmOizug"
      },
      "source": [
        "### 영상 파일이름 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_f5QIPziT6R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "18845a0c-3118-4895-845f-6276ee86e20a"
      },
      "source": [
        "imagePaths = sorted(list(paths.list_images('fashion_dataset')))\n",
        "random.shuffle(imagePaths)\n",
        "print(len(imagePaths))\n",
        "print(imagePaths[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "755\n",
            "['fashion_dataset/black_jeans/00000198.jpg', 'fashion_dataset/black_jeans/00000064.jpg', 'fashion_dataset/blue_shirt/00000079.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gIJx0rTjdMj"
      },
      "source": [
        "### 영상 읽기, 카테고리와 컬러 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cKf7OqHjXq-"
      },
      "source": [
        "data = []\n",
        "categoryLabels = []\n",
        "colorLabels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\timage = img_to_array(image)\n",
        "\tdata.append(image)\n",
        "\n",
        "\t(color, cat) = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
        "  # imagePath = 'fashion_dataset/black_shoes/00000048.jpg'\n",
        "  # color = 'black'\n",
        "  # cat = 'shoes'\n",
        "\tcategoryLabels.append(cat)\n",
        "\tcolorLabels.append(color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IME5dUwqilgV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cba935d9-802b-4e90-8fef-0b57bb976eb7"
      },
      "source": [
        "print(categoryLabels[:10])\n",
        "print(colorLabels[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['jeans', 'jeans', 'shirt', 'jeans', 'dress', 'dress', 'shoes', 'dress', 'shoes', 'shoes']\n",
            "['black', 'black', 'blue', 'black', 'red', 'blue', 'black', 'blue', 'black', 'black']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHIVMXWyjxov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "39b371ef-0795-49de-cb1c-0b51337b4981"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "print(len(data), len(categoryLabels), len(colorLabels))\n",
        "print(\"iamgePaths[0]=\", imagePaths[0])\n",
        "display(Image(imagePaths[0]))\n",
        "\n",
        "print(\"data[0]=\", data[0].shape)\n",
        "plt.imshow(data[0]/255)\n",
        "print(\"categoryLabels[0]=\", categoryLabels[0])\n",
        "print(\"colorLabels[0]=\", colorLabels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "755 755 755\n",
            "iamgePaths[0]= fashion_dataset/black_jeans/00000198.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "data[0]= (96, 96, 3)\n",
            "categoryLabels[0]= jeans\n",
            "colorLabels[0]= black\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CcZd2FUnTAb"
      },
      "source": [
        "### numpy로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFPjrQRCnSSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1bdad741-3736-44e7-adbd-2711e3fd9ac6"
      },
      "source": [
        "data = np.array(data, dtype=\"float\")\n",
        "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(len(imagePaths), data.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "# convert the label lists to NumPy arrays prior to binarization\n",
        "categoryLabels = np.array(categoryLabels)\n",
        "colorLabels = np.array(colorLabels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] data matrix: 755 images (163.08MB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJEmMrAXrmDP"
      },
      "source": [
        "## normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Xeo-Rorjwd"
      },
      "source": [
        "data = data/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G8ZqLqfnYRy"
      },
      "source": [
        "### 레이블 데이터를 one-hot 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2KnUkTEieV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "12150345-214a-4a56-c6cc-986ace6038c7"
      },
      "source": [
        "print(categoryLabels[:5])\n",
        "categoryLB = LabelBinarizer()\n",
        "categoryLabels = categoryLB.fit_transform(categoryLabels)\n",
        "print(categoryLabels[:5])\n",
        "\n",
        "\n",
        "print(colorLabels[:5])\n",
        "colorLB = LabelBinarizer()\n",
        "colorLabels = colorLB.fit_transform(colorLabels)\n",
        "print(colorLabels[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['jeans' 'jeans' 'shirt' 'jeans' 'dress']\n",
            "[[0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [1 0 0 0]]\n",
            "['black' 'black' 'blue' 'black' 'red']\n",
            "[[1 0 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXcJIhU1noje"
      },
      "source": [
        "### 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6H1tL3unAOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ff840655-321d-44d0-fbf3-ca73b7d7d8f8"
      },
      "source": [
        "(trainX, testX, trainCategoryY, testCategoryY, trainColorY, testColorY) = train_test_split(data, categoryLabels, colorLabels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(trainX.shape)\n",
        "print(trainCategoryY.shape)\n",
        "print(trainColorY.shape)\n",
        "\n",
        "print(testX.shape)\n",
        "print(testCategoryY.shape)\n",
        "print(testColorY.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(604, 96, 96, 3)\n",
            "(604, 4)\n",
            "(604, 3)\n",
            "(151, 96, 96, 3)\n",
            "(151, 4)\n",
            "(151, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vHgevIupt6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8405fa2d-4731-4047-a30a-fd600f09f808"
      },
      "source": [
        "CATEGORY_COUNT = categoryLabels.shape[-1]\n",
        "COLOR_COUNT = colorLabels.shape[-1]\n",
        "\n",
        "print(CATEGORY_COUNT)\n",
        "print(COLOR_COUNT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAcKr4uko_51"
      },
      "source": [
        "## 개별 모델로 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3gbBIm7oBMX"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "\n",
        "def build_category_model():\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(Input(IMAGE_DIMS))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(CATEGORY_COUNT, activation='softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "def build_color_model():\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(Input(IMAGE_DIMS))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(COLOR_COUNT, activation='softmax'))\n",
        "\n",
        "  return model  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh-cWdnw9YIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b34e64a1-24d4-4edf-a6cd-785d13b34959"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainCategoryY.shape)\n",
        "print(CATEGORY_COUNT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(604, 96, 96, 3)\n",
            "(604, 4)\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnwbSGt4I5Er"
      },
      "source": [
        "### 카테고리 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0CE4sh2pXrm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "dcddcaa6-e155-419c-8837-5fd86dead5a2"
      },
      "source": [
        "category_model = build_category_model()\n",
        "\n",
        "category_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "category_model.summary()\n",
        "\n",
        "\n",
        "category_model.fit(trainX, trainCategoryY, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = category_model.evaluate(testX, testCategoryY)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 94, 94, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 45, 45, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                309770    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 329,316\n",
            "Trainable params: 329,316\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 604 samples\n",
            "Epoch 1/5\n",
            "604/604 [==============================] - 1s 2ms/sample - loss: 245.4408 - acc: 0.2119\n",
            "Epoch 2/5\n",
            "604/604 [==============================] - 0s 476us/sample - loss: 62.8027 - acc: 0.2980\n",
            "Epoch 3/5\n",
            "604/604 [==============================] - 0s 472us/sample - loss: 18.4754 - acc: 0.3510\n",
            "Epoch 4/5\n",
            "604/604 [==============================] - 0s 454us/sample - loss: 1.3986 - acc: 0.2682\n",
            "Epoch 5/5\n",
            "604/604 [==============================] - 0s 457us/sample - loss: 1.3852 - acc: 0.2666\n",
            "151/151 [==============================] - 0s 1ms/sample - loss: 1.3854 - acc: 0.1987\n",
            "loss= 1.385439079328878\n",
            "acc= 0.1986755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_h8W_oHI_CZ"
      },
      "source": [
        "### 컬러 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-p1AcRT-IMJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "36f29462-639c-454d-c34d-68074e39a74a"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainColorY.shape)\n",
        "print(COLOR_COUNT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(604, 96, 96, 3)\n",
            "(604, 3)\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgm2tq2I-Sym",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "28e54f55-8e7b-4043-e40f-558e75d64034"
      },
      "source": [
        "color_model = build_color_model()\n",
        "\n",
        "color_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "color_model.summary()\n",
        "\n",
        "\n",
        "color_model.fit(trainX, trainColorY, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = color_model.evaluate(testX, testColorY)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 94, 94, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 45, 45, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                309770    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 329,305\n",
            "Trainable params: 329,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 604 samples\n",
            "Epoch 1/5\n",
            "604/604 [==============================] - 0s 618us/sample - loss: 57.2405 - acc: 0.2897\n",
            "Epoch 2/5\n",
            "604/604 [==============================] - 0s 466us/sample - loss: 34.1699 - acc: 0.3626\n",
            "Epoch 3/5\n",
            "604/604 [==============================] - 0s 467us/sample - loss: 9.8570 - acc: 0.4421\n",
            "Epoch 4/5\n",
            "604/604 [==============================] - 0s 469us/sample - loss: 1.3229 - acc: 0.7914\n",
            "Epoch 5/5\n",
            "604/604 [==============================] - 0s 462us/sample - loss: 0.7800 - acc: 0.8079\n",
            "151/151 [==============================] - 0s 728us/sample - loss: 0.8733 - acc: 0.7550\n",
            "loss= 0.8732589704311446\n",
            "acc= 0.7549669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlumccIP-YUu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1fdpl5c-iW_"
      },
      "source": [
        "## 다중 출력 모델로 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOyQbsVo-ke8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "\n",
        "def common_input_branch(input):\n",
        "\n",
        "  x = Conv2D(32, (3, 3))(input)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Conv2D(64, (3, 3))(x)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def category_branch(x):\n",
        "\n",
        "  x = Dense(10, activation='relu')(x)\n",
        "  x = Dense(10, activation='relu')(x)\n",
        "  x = Dense(CATEGORY_COUNT, activation='softmax', name='category_output')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def color_branch(x):\n",
        "\n",
        "  x = Dense(10, activation='relu')(x)\n",
        "  x = Dense(10, activation='relu')(x)\n",
        "  x = Dense(COLOR_COUNT, activation='softmax', name='color_output')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49vnw8ZSAEYN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "7bdd0161-19ac-4755-db2a-fb85214290a5"
      },
      "source": [
        "input = Input(IMAGE_DIMS)\n",
        "\n",
        "common_input = common_input_branch(input)\n",
        "category_output = category_branch(common_input)\n",
        "color_output = color_branch(common_input)\n",
        "\n",
        "multi_output_model = Model(input, [category_output, color_output])\n",
        "\n",
        "multi_output_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 96, 96, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 94, 94, 32)   896         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 47, 47, 32)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 45, 45, 64)   18496       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 22, 22, 64)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 30976)        0           max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 10)           309770      flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 10)           309770      flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 10)           110         dense_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 10)           110         dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "category_output (Dense)         (None, 4)            44          dense_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "color_output (Dense)            (None, 3)            33          dense_31[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 639,229\n",
            "Trainable params: 639,229\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SftqPQsKAHCU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abe619d9-0198-4ddc-bc75-b45e19ab5bda"
      },
      "source": [
        "losses = { \"category_output\":\"categorical_crossentropy\", \"color_output\":\"categorical_crossentropy\"}\n",
        "loss_weights = { \"category_output\":1.0, \"color_output\":1.0}\n",
        "\n",
        "# color_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "multi_output_model.compile(optimizer=\"adam\", loss=losses, loss_weights=loss_weights, metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# color_model.fit(trainX, trainColorY, epochs=5, verbose=1, batch_size=128)\n",
        "multi_output_model.fit(trainX, {\"category_output\":trainCategoryY, \"color_output\":trainColorY}, epochs=50, verbose=1, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 604 samples\n",
            "Epoch 1/50\n",
            "604/604 [==============================] - 1s 880us/sample - loss: 273.9671 - category_output_loss: 97.8160 - color_output_loss: 170.2181 - category_output_acc: 0.2997 - color_output_acc: 0.3957\n",
            "Epoch 2/50\n",
            "604/604 [==============================] - 0s 547us/sample - loss: 75.8908 - category_output_loss: 1.6496 - color_output_loss: 70.9485 - category_output_acc: 0.3543 - color_output_acc: 0.3560\n",
            "Epoch 3/50\n",
            "604/604 [==============================] - 0s 524us/sample - loss: 23.3261 - category_output_loss: 10.0313 - color_output_loss: 12.6673 - category_output_acc: 0.3146 - color_output_acc: 0.7169\n",
            "Epoch 4/50\n",
            "604/604 [==============================] - 0s 509us/sample - loss: 7.0968 - category_output_loss: 1.3753 - color_output_loss: 5.5770 - category_output_acc: 0.3113 - color_output_acc: 0.7997\n",
            "Epoch 5/50\n",
            "604/604 [==============================] - 0s 497us/sample - loss: 3.7273 - category_output_loss: 1.3859 - color_output_loss: 2.2623 - category_output_acc: 0.2964 - color_output_acc: 0.8924\n",
            "Epoch 6/50\n",
            "604/604 [==============================] - 0s 494us/sample - loss: 2.7558 - category_output_loss: 1.3853 - color_output_loss: 1.3960 - category_output_acc: 0.2964 - color_output_acc: 0.9354\n",
            "Epoch 7/50\n",
            "604/604 [==============================] - 0s 492us/sample - loss: 2.6358 - category_output_loss: 1.3849 - color_output_loss: 1.2405 - category_output_acc: 0.2964 - color_output_acc: 0.9536\n",
            "Epoch 8/50\n",
            "604/604 [==============================] - 0s 488us/sample - loss: 2.2123 - category_output_loss: 1.3844 - color_output_loss: 0.8146 - category_output_acc: 0.2964 - color_output_acc: 0.9454\n",
            "Epoch 9/50\n",
            "604/604 [==============================] - 0s 488us/sample - loss: 1.8789 - category_output_loss: 1.3836 - color_output_loss: 0.4709 - category_output_acc: 0.2964 - color_output_acc: 0.9619\n",
            "Epoch 10/50\n",
            "604/604 [==============================] - 0s 504us/sample - loss: 1.6876 - category_output_loss: 1.3834 - color_output_loss: 0.2977 - category_output_acc: 0.2964 - color_output_acc: 0.9818\n",
            "Epoch 11/50\n",
            "604/604 [==============================] - 0s 488us/sample - loss: 1.5532 - category_output_loss: 1.3827 - color_output_loss: 0.1653 - category_output_acc: 0.2964 - color_output_acc: 0.9834\n",
            "Epoch 12/50\n",
            "604/604 [==============================] - 0s 483us/sample - loss: 1.4506 - category_output_loss: 1.3819 - color_output_loss: 0.0647 - category_output_acc: 0.2964 - color_output_acc: 0.9901\n",
            "Epoch 13/50\n",
            "604/604 [==============================] - 0s 491us/sample - loss: 1.5581 - category_output_loss: 1.3812 - color_output_loss: 0.1851 - category_output_acc: 0.2964 - color_output_acc: 0.9884\n",
            "Epoch 14/50\n",
            "604/604 [==============================] - 0s 495us/sample - loss: 1.6687 - category_output_loss: 1.3811 - color_output_loss: 0.2798 - category_output_acc: 0.2964 - color_output_acc: 0.9752\n",
            "Epoch 15/50\n",
            "604/604 [==============================] - 0s 489us/sample - loss: 1.4232 - category_output_loss: 1.3809 - color_output_loss: 0.0404 - category_output_acc: 0.2964 - color_output_acc: 0.9917\n",
            "Epoch 16/50\n",
            "604/604 [==============================] - 0s 492us/sample - loss: 1.4415 - category_output_loss: 1.3797 - color_output_loss: 0.0582 - category_output_acc: 0.2964 - color_output_acc: 0.9934\n",
            "Epoch 17/50\n",
            "604/604 [==============================] - 0s 490us/sample - loss: 1.4777 - category_output_loss: 1.3795 - color_output_loss: 0.0981 - category_output_acc: 0.2964 - color_output_acc: 0.9851\n",
            "Epoch 18/50\n",
            "604/604 [==============================] - 0s 484us/sample - loss: 1.4187 - category_output_loss: 1.3788 - color_output_loss: 0.0377 - category_output_acc: 0.2964 - color_output_acc: 0.9934\n",
            "Epoch 19/50\n",
            "604/604 [==============================] - 0s 489us/sample - loss: 1.3980 - category_output_loss: 1.3784 - color_output_loss: 0.0189 - category_output_acc: 0.2964 - color_output_acc: 0.9967\n",
            "Epoch 20/50\n",
            "604/604 [==============================] - 0s 497us/sample - loss: 1.3856 - category_output_loss: 1.3779 - color_output_loss: 0.0074 - category_output_acc: 0.2964 - color_output_acc: 0.9967\n",
            "Epoch 21/50\n",
            "604/604 [==============================] - 0s 489us/sample - loss: 1.3833 - category_output_loss: 1.3773 - color_output_loss: 0.0058 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 22/50\n",
            "604/604 [==============================] - 0s 492us/sample - loss: 1.3786 - category_output_loss: 1.3769 - color_output_loss: 0.0016 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 23/50\n",
            "604/604 [==============================] - 0s 494us/sample - loss: 1.3813 - category_output_loss: 1.3766 - color_output_loss: 0.0050 - category_output_acc: 0.2964 - color_output_acc: 0.9967\n",
            "Epoch 24/50\n",
            "604/604 [==============================] - 0s 488us/sample - loss: 1.3810 - category_output_loss: 1.3756 - color_output_loss: 0.0048 - category_output_acc: 0.2964 - color_output_acc: 0.9967\n",
            "Epoch 25/50\n",
            "604/604 [==============================] - 0s 480us/sample - loss: 1.3796 - category_output_loss: 1.3753 - color_output_loss: 0.0039 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 26/50\n",
            "604/604 [==============================] - 0s 481us/sample - loss: 1.3929 - category_output_loss: 1.3754 - color_output_loss: 0.0169 - category_output_acc: 0.2964 - color_output_acc: 0.9967\n",
            "Epoch 27/50\n",
            "604/604 [==============================] - 0s 491us/sample - loss: 1.3960 - category_output_loss: 1.3746 - color_output_loss: 0.0278 - category_output_acc: 0.2964 - color_output_acc: 0.9950\n",
            "Epoch 28/50\n",
            "604/604 [==============================] - 0s 487us/sample - loss: 1.5142 - category_output_loss: 1.3739 - color_output_loss: 0.1336 - category_output_acc: 0.2964 - color_output_acc: 0.9851\n",
            "Epoch 29/50\n",
            "604/604 [==============================] - 0s 485us/sample - loss: 1.6211 - category_output_loss: 1.3739 - color_output_loss: 0.2524 - category_output_acc: 0.2964 - color_output_acc: 0.9768\n",
            "Epoch 30/50\n",
            "604/604 [==============================] - 0s 489us/sample - loss: 1.4521 - category_output_loss: 1.3735 - color_output_loss: 0.0742 - category_output_acc: 0.2964 - color_output_acc: 0.9834\n",
            "Epoch 31/50\n",
            "604/604 [==============================] - 0s 484us/sample - loss: 1.4412 - category_output_loss: 1.3725 - color_output_loss: 0.0761 - category_output_acc: 0.2964 - color_output_acc: 0.9934\n",
            "Epoch 32/50\n",
            "604/604 [==============================] - 0s 490us/sample - loss: 1.4114 - category_output_loss: 1.3726 - color_output_loss: 0.0367 - category_output_acc: 0.2964 - color_output_acc: 0.9950\n",
            "Epoch 33/50\n",
            "604/604 [==============================] - 0s 496us/sample - loss: 1.3755 - category_output_loss: 1.3720 - color_output_loss: 0.0031 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 34/50\n",
            "604/604 [==============================] - 0s 503us/sample - loss: 1.4027 - category_output_loss: 1.3721 - color_output_loss: 0.0290 - category_output_acc: 0.2964 - color_output_acc: 0.9967\n",
            "Epoch 35/50\n",
            "604/604 [==============================] - 0s 482us/sample - loss: 1.4026 - category_output_loss: 1.3712 - color_output_loss: 0.0292 - category_output_acc: 0.2964 - color_output_acc: 0.9950\n",
            "Epoch 36/50\n",
            "604/604 [==============================] - 0s 488us/sample - loss: 1.3919 - category_output_loss: 1.3713 - color_output_loss: 0.0196 - category_output_acc: 0.2964 - color_output_acc: 0.9917\n",
            "Epoch 37/50\n",
            "604/604 [==============================] - 0s 485us/sample - loss: 1.3769 - category_output_loss: 1.3711 - color_output_loss: 0.0057 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 38/50\n",
            "604/604 [==============================] - 0s 486us/sample - loss: 1.3827 - category_output_loss: 1.3709 - color_output_loss: 0.0113 - category_output_acc: 0.2964 - color_output_acc: 0.9950\n",
            "Epoch 39/50\n",
            "604/604 [==============================] - 0s 500us/sample - loss: 1.3878 - category_output_loss: 1.3698 - color_output_loss: 0.0167 - category_output_acc: 0.2964 - color_output_acc: 0.9967\n",
            "Epoch 40/50\n",
            "604/604 [==============================] - 0s 500us/sample - loss: 1.3781 - category_output_loss: 1.3702 - color_output_loss: 0.0076 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 41/50\n",
            "604/604 [==============================] - 0s 504us/sample - loss: 1.3792 - category_output_loss: 1.3701 - color_output_loss: 0.0089 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 42/50\n",
            "604/604 [==============================] - 0s 495us/sample - loss: 1.3755 - category_output_loss: 1.3698 - color_output_loss: 0.0079 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 43/50\n",
            "604/604 [==============================] - 0s 490us/sample - loss: 1.3720 - category_output_loss: 1.3680 - color_output_loss: 0.0027 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 44/50\n",
            "604/604 [==============================] - 0s 488us/sample - loss: 1.3741 - category_output_loss: 1.3686 - color_output_loss: 0.0050 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 45/50\n",
            "604/604 [==============================] - 0s 493us/sample - loss: 1.3707 - category_output_loss: 1.3684 - color_output_loss: 0.0019 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 46/50\n",
            "604/604 [==============================] - 0s 496us/sample - loss: 1.3729 - category_output_loss: 1.3683 - color_output_loss: 0.0043 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 47/50\n",
            "604/604 [==============================] - 0s 494us/sample - loss: 1.3695 - category_output_loss: 1.3682 - color_output_loss: 0.0013 - category_output_acc: 0.2964 - color_output_acc: 0.9983\n",
            "Epoch 48/50\n",
            "604/604 [==============================] - 0s 488us/sample - loss: 1.3693 - category_output_loss: 1.3684 - color_output_loss: 0.0013 - category_output_acc: 0.2964 - color_output_acc: 1.0000\n",
            "Epoch 49/50\n",
            "604/604 [==============================] - 0s 495us/sample - loss: 1.3690 - category_output_loss: 1.3670 - color_output_loss: 0.0013 - category_output_acc: 0.2964 - color_output_acc: 1.0000\n",
            "Epoch 50/50\n",
            "604/604 [==============================] - 0s 494us/sample - loss: 1.3683 - category_output_loss: 1.3679 - color_output_loss: 9.5770e-04 - category_output_acc: 0.2964 - color_output_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff07fae0fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHH3al7zB4uK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d3e16a18-ede1-4470-8306-a02afdcec203"
      },
      "source": [
        "loss, category_loss, color_loss, category_acc, color_acc = multi_output_model.evaluate(testX, {\"category_output\":testCategoryY, \"color_output\":testColorY})\n",
        "print(\"loss=\",loss)\n",
        "print(\"categoyr_loss=\", category_loss)\n",
        "print(\"color_loss=\", color_loss)\n",
        "print(\"category_acc=\", category_acc)\n",
        "print(\"color_acc=\", color_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 0s 1ms/sample - loss: 2.4729 - category_output_loss: 1.3549 - color_output_loss: 1.2244 - category_output_acc: 0.3377 - color_output_acc: 0.9603\n",
            "loss= 2.472860945771072\n",
            "categoyr_loss= 1.3549242\n",
            "color_loss= 1.2244413\n",
            "category_acc= 0.33774835\n",
            "color_acc= 0.9602649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGPuLHteCIso"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}